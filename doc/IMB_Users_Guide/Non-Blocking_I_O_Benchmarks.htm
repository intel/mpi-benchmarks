
<!doctype HTML public "-//W3C//DTD HTML 4.0 Frameset//EN">
<!-- saved from url=(0014)about:internet -->
<html>
<head>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 <meta name="generator" content="Adobe RoboHelp 2015">
<title>Nonblocking I/O Benchmarks</title>
<link rel="StyleSheet" href="intel_css_styles.css" type="text/css">
 <link rel="StyleSheet" href="intel_css_styles.css" type="text/css">
<style title="hcp" type="text/css">
<!--
ul.hcp1 { list-style:disc; }
-->
</style>
</head>
<script src="NavScript.js" language="JavaScript1.2" type="text/javascript"></script>
<script language="JavaScript1.2" type="text/javascript">WriteNavLink(0);</script>
<body>
<script type="text/javascript" src="ehlpdhtm.js" language="JavaScript1.2"></script>

 <div style="width: 100%; position: relative;" id="header">
	<p style="font-style: italic;">Intel® 
	 MPI Benchmarks User Guide and Methodology Description</p>
</div>


<h1><a name="Non_blocking_I_O" id="Non_blocking_I_O"></a>IMB-IO Non-blocking Benchmarks</h1>
<p>Intel® MPI Benchmarks implements blocking and nonblocking modes of the IMB-IO benchmarks as different benchmark flavors. The <samp class="codeph">Read</samp> and <samp class="codeph">Write</samp> components of the blocking benchmark name are replaced&#160;for nonblocking flavors by <samp class="codeph">IRead</samp> and <samp class="codeph">IWrite</samp>, respectively.</p>
<p>The definitions of blocking and nonblocking flavors are identical, except for their behavior in regard to:</p>
<ul class="hcp1">
<li>
<p>Aggregation. The nonblocking versions only run in the non-aggregate mode.</p>
</li>
<li>
<p>Synchronism. Only the meaning of an elementary transfer differs from the equivalent blocking benchmark.</p>
</li>
</ul>
<p>Basically, an elementary transfer looks as follows:</p>
<pre>
time = MPI_Wtime()
for ( i=0; i&lt;n_sample; i++ )
{
    Initiate transfer
    Exploit CPU
    Wait for the end of transfer
}
time = (MPI_Wtime()-time)/n_sample
</pre>
<p>The <samp class="codeph">Exploit CPU</samp> section in the above example is arbitrary. Intel® MPI Benchmarks exploits CPU as described below.</p>
<h2>Exploiting CPU</h2>
<p>Intel® MPI Benchmarks uses the following method to exploit the CPU. A kernel loop is executed repeatedly. The kernel is a fully vectorizable multiplication of a 100x100 matrix with a vector. The function is scalable in the following way:</p>
<p><samp class="codeph">IMB_cpu_exploit(float desired_time, int initialize);</samp></p>
<p>The input value of <samp class="codeph">desired_time</samp> determines the time for the function to execute the kernel loop, with a slight variance. At the very beginning, the function is called with <samp class="codeph">initialize=1</samp> and an input value for <samp class="codeph">desired_time</samp>. This determines an Mflop/s rate and a timing <samp class="codeph">t_CPU</samp>, as close as possible to <samp class="codeph">desired_time</samp>, obtained by running without any obstruction. During the actual benchmarking, <samp class="codeph">IMB_cpu_exploit</samp> is called with <samp class="codeph">initialize=0</samp>, concurrently with the particular I/O action, and always performs the same type and number of operations as in the initialization step.</p>
<h2>Displaying Results</h2>
<p>Three timings are crucial to interpret the behavior of nonblocking I/O, overlapped with CPU exploitation:</p>
<ul class="hcp1">
<li>
<p><samp class="codeph">t_pure</samp> is the time for the corresponding pure blocking I/O action, non-overlapping with CPU activity</p>
</li>
<li>
<p><samp class="codeph">t_CPU</samp>&#160;&#160;is the time the <samp class="codeph">IMB_cpu_exploit</samp> periods (running concurrently with nonblocking I/O) would use when running dedicated</p>
</li>
<li>
<p><samp class="codeph">t_ovrl</samp> is the time for the analogous nonblocking I/O action, concurrent with CPU activity (exploiting <samp class="codeph">t_CPU</samp> when running dedicated)</p>
</li>
</ul>
<p>A perfect overlap means: <samp class="codeph">t_ovrl&#160;=&#160;max(t_pure,t_CPU)</samp></p>
<p>No overlap means: <samp class="codeph">t_ovrl&#160;=&#160;t_pure+t_CPU</samp>.</p>
<p>The actual amount of overlap is: <samp class="codeph">&#160;</samp></p>
<p><samp class="codeph">overlap=(t_pure+t_CPU-t_ovrl)/min(t_pure,t_CPU)</samp>(*)</p>
<p>The Intel® MPI Benchmarks result tables report the timings <samp class="codeph">t_ovrl, t_pure, t_CPU</samp> and the estimated overlap obtained by the (*) formula above. At the beginning of a run, the Mflop/s rate is corresponding to the <samp class="codeph">t_CPU</samp> displayed.</p>
</body>
</html>
